---
title: 'Wizard Wells: Formatting'
author: "Jill Deines"
date: "April 11, 2018"
output: 
  html_document:
    toc: true
    toc_float: true
    keep_md: true
---

Goal: Load well data from Kansas's WIZARD database, explore dataset, and format for subsequent use.

Update 5/27/2018: removing bad well flagged by Jim Butler

Note: well data is not included in this repo to leave personal data access to the management of the KGS and WIZARD database. The data used here (site and wlevel data) was downloaded for GMD4 on April 11, 2018 from http://www.kgs.ku.edu/Magellan/WaterLevels/index.html



**R Packages Needed**


```r
library(tidyverse) # for ggplot2, tidyr, dplyr
library(sf)
library(lubridate)

# get filepath to R project on local system
library(here)
mainDir <- here()

sessionInfo()
```

```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS  10.14
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] here_0.1        lubridate_1.7.4 sf_0.6-3        forcats_0.3.0  
##  [5] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1    
##  [9] tidyr_0.8.1     tibble_1.4.2    ggplot2_3.1.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_0.2.4 haven_1.1.2      lattice_0.20-35  colorspace_1.3-2
##  [5] htmltools_0.3.6  yaml_2.2.0       rlang_0.2.2      e1071_1.7-0     
##  [9] pillar_1.3.0     glue_1.3.0       withr_2.1.2      DBI_1.0.0       
## [13] modelr_0.1.2     readxl_1.1.0     bindrcpp_0.2.2   bindr_0.1.1     
## [17] plyr_1.8.4       munsell_0.5.0    gtable_0.2.0     cellranger_1.1.0
## [21] rvest_0.3.2      evaluate_0.11    knitr_1.20       class_7.3-14    
## [25] broom_0.5.0      Rcpp_0.12.19     scales_1.0.0     backports_1.1.2 
## [29] classInt_0.2-3   jsonlite_1.5     hms_0.4.2        digest_0.6.16   
## [33] stringi_1.2.4    grid_3.5.1       rprojroot_1.3-2  cli_1.0.0       
## [37] tools_3.5.1      magrittr_1.5     lazyeval_0.2.1   crayon_1.3.4    
## [41] pkgconfig_2.0.2  xml2_1.2.0       spData_0.2.9.3   assertthat_0.2.0
## [45] rmarkdown_1.10   httr_1.3.1       rstudioapi_0.7   R6_2.2.2        
## [49] units_0.6-1      nlme_3.1-137     compiler_3.5.1
```

# Load Data

## Study Area Boundaries

```r
gisDir <- paste0(mainDir, '/data/GIS/boundaries')
datum <- 4269 #NAD83 = 4269

# load and re-project to NAD83 (to match WIZARD lat/long)
sheridan <- read_sf(paste0(gisDir,'/Sheridan6_fromKGS_sd6.shp')) %>%
  st_transform(4269)
null9 <- read_sf(paste0(gisDir,'/Sheridan_Null_Geo9.shp')) %>%
  st_transform(4269) %>%
  st_buffer(0)
```

```
## Warning in st_buffer.sfc(st_geometry(x), dist, nQuadSegs): st_buffer does
## not correctly buffer longitude/latitude data
```

```
## dist is assumed to be in decimal degrees (arc_degrees).
```

```r
gmd4 <- read_sf(paste0(gisDir,'/KS_GMD4.kml')) %>%
  st_transform(4269)

# combine study areas
aoi <- sheridan %>%
  mutate(masterid = 'sheridan') %>%
  select(masterid) %>%
  rbind(., null9 %>% select(masterid))

# buffer the study regions and dissolve (to filter wells for kriging)
aoiBuff <- aoi %>% 
  st_transform(5070) %>% 
  st_buffer(10000) %>% 
  st_transform(4269) %>%
  st_union() %>%
  st_sf() 
names(aoiBuff) <- 'geometry'
st_geometry(aoiBuff) <- 'geometry'
aoiBuff$masterid = 'buffer'

# # export for external data processing
# write_sf(aoiBuff, paste0(gisDir,'/Combined_Null9_S6_10kmBuff.shp'))

# punch holes in buffer
buffHole <- st_difference(aoiBuff, sheridan)
```

```
## although coordinates are longitude/latitude, st_difference assumes that they are planar
```

```
## Warning: attribute variables are assumed to be spatially constant
## throughout all geometries
```

```r
buffHoles <- st_difference(buffHole, null9) %>% select('masterid')
```

```
## although coordinates are longitude/latitude, st_difference assumes that they are planar
```

```
## Warning: attribute variables are assumed to be spatially constant
## throughout all geometries
```

```r
plot(buffHoles)
```

![](../figure/00.20_wizardFormatting/loadPolys-1.png)<!-- -->

```r
# new buffered aoi polygons
aoi2 <- aoi %>%
  rbind(., buffHoles)
plot(aoi2)
```

![](../figure/00.20_wizardFormatting/loadPolys-2.png)<!-- -->

```r
# # export for external data processing
# write_sf(aoi2, paste0(gisDir,'/Combined_Null9_S6_10kmBuff_indvlPolys.shp'))
```

## Well Data
site and wlevel data downloaded for GMD4 on April 11, 2018 
from http://www.kgs.ku.edu/Magellan/WaterLevels/index.html


```r
wellDir <- paste0(mainDir, '/data/wellData/WIZARD')
siteFile <- 'raw/sites20180412183715707_GMD4_depthWells.txt'
wlevelFile <- 'raw/wlevel20180412183715707_GMD4_depthWells.txt'

# load site locations
sites <- read_csv(paste0(wellDir,'/',siteFile)) %>%
  select(c(USGS_ID, LATITUDE, LONGITUDE, 
           LAND_SURFACE_ALTITUDE, LAND_SURFACE_ALTITUDE_ACCURACY,
           ALTITUDE_DATUM, USE_OF_SITE_PRIMARY,
           USE_OF_WATER_PRIMARY))
```

```
## Parsed with column specification:
## cols(
##   .default = col_character(),
##   USGS_ID = col_double(),
##   STATE_CODE = col_integer(),
##   COUNTY_CODE = col_integer(),
##   LATITUDE = col_double(),
##   LONGITUDE = col_double(),
##   SECTION_ = col_integer(),
##   SUBDIVISION_WELL_NUMBER = col_integer(),
##   TOWNSHIP = col_integer(),
##   RANGE = col_integer(),
##   MERIDIAN = col_integer(),
##   LAND_SURFACE_ALTITUDE = col_double(),
##   LAND_SURFACE_ALTITUDE_ACCURACY = col_double(),
##   HYDROLOGIC_UNIT_CODE = col_integer(),
##   DEPTH_OF_WELL = col_double(),
##   INV_WATER_LEVEL = col_double(),
##   GROUNDWATER_MGMT_DISTRICT = col_integer(),
##   DEPTH_TO_BEDROCK = col_integer(),
##   WATER_LEVEL_REPORT_REGION = col_integer(),
##   MAP_SCALE = col_integer(),
##   DRAINAGE_BASIN_CODE = col_integer()
##   # ... with 1 more columns
## )
```

```
## See spec(...) for full column specifications.
```

```r
# load water levels
wlevels <- read_csv(paste0(wellDir,'/',wlevelFile)) %>%
  select(c(USGS_ID,  MEASUREMENT_DATE_AND_TIME, DEPTH_TO_WATER, ACCURACY_CODE, STATUS))
```

```
## Parsed with column specification:
## cols(
##   USGS_ID = col_double(),
##   SEQUENCE_NUMBER = col_integer(),
##   MEASUREMENT_DATE_AND_TIME = col_character(),
##   DEPTH_TO_WATER = col_double(),
##   STATUS = col_character(),
##   METHOD = col_character(),
##   ACCURACY_CODE = col_integer(),
##   ATTEMPTS = col_integer(),
##   AGENCY = col_character(),
##   TAG_NUMBER = col_integer(),
##   OIL_ON_WATER = col_character(),
##   LATITUDE_GPS = col_double(),
##   LONGITUDE_GPS = col_double(),
##   TAPE_HOLD = col_integer(),
##   CHALK_CUT = col_double(),
##   INITIALS = col_character(),
##   CHALK_CUT_QUALITY = col_character(),
##   WEIGHTED_TAPE = col_character()
## )
```

```
## Warning in rbind(names(probs), probs_f): number of columns of result is not
## a multiple of vector length (arg 1)
```

```
## Warning: 30 parsing failures.
## row # A tibble: 5 x 5 col     row col     expected        actual file                                expected   <int> <chr>   <chr>           <chr>  <chr>                               actual 1  2768 TAPE_H… no trailing ch… .35    '/Users/deinesji/Documents/code_gi… file 2  3479 TAPE_H… no trailing ch… .55    '/Users/deinesji/Documents/code_gi… row 3  6658 TAPE_H… no trailing ch… .34    '/Users/deinesji/Documents/code_gi… col 4  6808 TAPE_H… no trailing ch… .81    '/Users/deinesji/Documents/code_gi… expected 5  6824 TAPE_H… no trailing ch… .28    '/Users/deinesji/Documents/code_gi…
## ... ................. ... .......................................................................... ........ .......................................................................... ...... .......................................................................... .... .......................................................................... ... .......................................................................... ... .......................................................................... ........ ..........................................................................
## See problems(...) for more details.
```

Note parsing errors aren't a problem

## Subset wells for study area
Hm maybe with a buffer in the future?


```r
# spatialize well dataset
sitesLL <- st_as_sf(sites, coords = c('LONGITUDE','LATITUDE'), crs = 4269)

# extract points in both aois
wellsIn <- st_join(sitesLL, aoi2) %>% filter(!is.na(masterid))
```

```
## although coordinates are longitude/latitude, st_intersects assumes that they are planar
```

```r
# # plot
# plot(aoi2, main='water level wells, any year')
# plot(wellsIn[2], add=TRUE, col='black')
```

## Join Water Level Data and Drop Excess
Add water level data to site wells; parse some date columns. Keep only relevant columns


```r
# add water levels for subsetted wells
wellsInData <- wellsIn %>%
  left_join(wlevels, by = 'USGS_ID')

# make some date columns
wellsInData$Date <- mdy(wellsInData$MEASUREMENT_DATE_AND_TIME)
wellsInData$DOY <- yday(wellsInData$Date)
wellsInData$Year <- year(wellsInData$Date)
```

## Remove well
USGS ID - 392124100364001 per communication with Jim


```r
# check if well is in dataset
392124100364001 %in% wellsInData$USGS_ID
```

```
## [1] TRUE
```

```r
# remove well, reduce columns
wellsInData2 <- wellsInData %>%
  filter(USGS_ID != 392124100364001) %>%
  select(c(USGS_ID, masterid, Date, DOY, Year, DEPTH_TO_WATER,
           LAND_SURFACE_ALTITUDE, STATUS, ACCURACY_CODE))
```


# Process Data

## Time Filters
filter for relevant observation time and years. Filter includes:

* removing measurements outside of winter months (keep December 10 - February 28 measurements)
* adjusting year to better straddle the new year: so if DOY is < 60, decrease year by 1 (in other words, use the same year as the irrigation pumping season)
* starting at 1996 when KGS took over = more robust (so start date = December 2016, since my valid measurements can span the new year)


```r
# filter days
startDate <- '1996-12-01'
earliestDOY <- 344
latestDOY <- 59

# filter by DOY: keep only winter measurements
wellsWinter <- wellsInData2 %>% 
  filter(DOY <= latestDOY | DOY >= earliestDOY)

# adjust years to indicate year of pumping
wellsWinter$YearAdjusted <- wellsWinter$Year
for (i in 1:nrow(wellsWinter)) {
  if (wellsWinter$DOY[i] < 60) {
    wellsWinter[i,'YearAdjusted'] <- wellsWinter$Year[i] - 1
  }
}

# keep more recent data
length(unique(wellsWinter$USGS_ID))
```

```
## [1] 109
```

```r
wellsWinterRecent <- wellsWinter %>% filter(Date >= startDate)

length(unique(wellsWinterRecent$USGS_ID))
```

```
## [1] 70
```

```r
# when do recent well winter measurements tend to occur?
ggplot(wellsWinterRecent, aes(DOY)) +
  geom_histogram() +
  facet_wrap(~Year) +
  theme_bw() +
  ggtitle(paste0('Well Reading Date between ', earliestDOY, ' and ', latestDOY))
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](../figure/00.20_wizardFormatting/filterData-1.png)<!-- -->

```r
# compare against all wells
ggplot(wellsInData2 %>% filter(Date >= startDate), aes(DOY)) +
  geom_histogram() +
  geom_vline(xintercept = earliestDOY, col = 'red') +
  geom_vline(xintercept = latestDOY, col= 'red') +
  facet_wrap(~Year) +
  theme_bw() +
  ggtitle(paste0('Well Reading Date between ', earliestDOY, ' and ', latestDOY))
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](../figure/00.20_wizardFormatting/filterData-2.png)<!-- -->

## check for bad data
The Status and Accuracy code columns have some qa/qc materials

There are some rows without an entry; the metadata for status says "if blank, the water level was static" so I guess that's a good indication.

There are some Accuracy Code columns with NA's (98) - I remove these (many seem to be multiple measurements of the same well within the target period, perhaps measured with a different system that doens't record accuracy)


```r
# remove rows with NA depths
wells2 <- wellsWinterRecent %>% filter(!is.na(DEPTH_TO_WATER))

# Check accuracy codes
unique(wells2$ACCURACY_CODE)  # 2 is great!
```

```
## [1]  2 NA
```

```r
sum(is.na(wells2$ACCURACY_CODE))
```

```
## [1] 112
```

```r
wells2b <- wells2 %>% filter(!is.na(ACCURACY_CODE))

# check existing statuses
unique(wells2b$STATUS)
```

```
## [1] NA  "A"
```

```r
wells2b %>% filter(STATUS == 'A')
```

```
## Simple feature collection with 2 features and 10 fields
## geometry type:  POINT
## dimension:      XY
## bbox:           xmin: -100.9904 ymin: 39.29048 xmax: -100.6454 ymax: 39.36823
## epsg (SRID):    4269
## proj4string:    +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs
##        USGS_ID masterid       Date DOY Year DEPTH_TO_WATER
## 1 3.922101e+14 sheridan 2016-12-29 364 2016         223.11
## 2 3.917241e+14   buffer 2017-01-03   3 2017         146.50
##   LAND_SURFACE_ALTITUDE STATUS ACCURACY_CODE YearAdjusted
## 1                  2941      A             2         2016
## 2                  3135      A             2         2016
##                     geometry
## 1 POINT (-100.6454 39.36823)
## 2 POINT (-100.9904 39.29048)
```

```r
# remove 4 anomalous recoreds
wells3_0 <- wells2b %>% filter(is.na(STATUS)) %>%
  select(-c(STATUS))
```

## Collapse Redundant Readings
There are several cases where multiple well levels were recorded for 1 well during each "data season" - currently December 10 - February 28.

Collapse these into 1 value per well per year - using mean until told otherwise.

Note visual inspection of these instances mostly revealed these were measurements recorded on the same day or within a few days with depth values quite similar (off by some hundredths)

Also add a simpler well id column so it's short enough to see when printed to console


```r
# add a simpler/shorter wellID
wellKeyUpdater <- data.frame(USGS_ID = unique(wells3_0$USGS_ID),
                             wellID = 1:length(unique(wells3_0$USGS_ID)))

# get mean depth level for each well, in each adjusted year
wells3_1 <- wells3_0 %>%
  left_join(wellKeyUpdater, by = "USGS_ID") %>% 
 # group by wellID and YearAdjusted, add other columns simply to retain values
  group_by(USGS_ID, masterid, wellID, LAND_SURFACE_ALTITUDE, YearAdjusted) %>%
  summarize(Depth_ft = mean(DEPTH_TO_WATER),
            Date = mean(Date), DOY = mean(DOY), Year = mean(Year)) %>%
  arrange(wellID, YearAdjusted)

# add a lat and long column based on sf geometry column
coords <- st_coordinates(wells3_1) 
wells3 <- cbind(wells3_1, coords)
```

## Convert Units 
conversions:

* convert depth-to-water from feet to meters
* convert land surface altitude to meters (Sea Level Datum of 1929) - assumed to be in feet although Metadata doesn't specify
* derive water table elevation


```r
# feet to meters
wells3$Depth_m <- wells3$Depth_ft * 0.3048 
wells3$SurfaceAltitude_m <- wells3$LAND_SURFACE_ALTITUDE * 0.3048 

# derive water table elevation
wells3$wtElev_m <- wells3$SurfaceAltitude_m - wells3$Depth_m
```


## Calculate Change in Water Level
Include a column for change in water level

Calculated as change since previous year, with negatives indicating a water level drop. Calculated by well. Also flags the number of years since last measurement, so "change in water level" values over more than 1 year could be omitted.

Also add a "better" (shorter) wellID


```r
# calculate the change in water table elevation since previous measurement, by well
wells4 <- wells3 %>%
  group_by(wellID) %>%
  arrange(wellID,YearAdjusted) %>%
  mutate(changeInWaterLevel = c(NA, diff(wtElev_m))) %>%
  # and add the number of years that "change" spanned
  mutate(changeInterval = c(NA, diff(YearAdjusted))) %>%
  mutate(DOY = as.integer(DOY), 
         changeInterval = as.integer(changeInterval)) %>%
  rename(YearAdj = YearAdjusted,
         dWtElevm = changeInWaterLevel,
         Interval = changeInterval) %>%
  # and select/order columns to retain
  select(c(wellID, masterid, Date, DOY, Year, YearAdj, Depth_m, 
           wtElev_m, dWtElevm, Interval, X, Y))
```

Note I removed the USGS_ID because it caused a "too long" error when writing out the shapefile and I didn't feel like fixing it.

## Summarize Data
Some stats on the remaining data


```r
# how many unique wells?
length(unique(wells4$wellID))
```

```
## [1] 63
```

```r
# unique wells by region?
wells4 %>% 
  group_by(masterid) %>%
  summarize(n = n_distinct(wellID))
```

```
## Simple feature collection with 3 features and 2 fields
## geometry type:  MULTIPOINT
## dimension:      XY
## bbox:           xmin: -101.0879 ymin: 39.23339 xmax: -100.3692 ymax: 39.56223
## epsg (SRID):    4269
## proj4string:    +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs
## # A tibble: 3 x 3
##   masterid      n                                                 geometry
##   <chr>     <int>                                         <MULTIPOINT [°]>
## 1 buffer       45 (-101.0879 39.33988, -101.0801 39.41261, -101.0678 39.3…
## 2 null_geo9     9 (-100.9365 39.37962, -100.9325 39.46113, -100.9202 39.4…
## 3 sheridan      9 (-100.6952 39.37987, -100.6458 39.409, -100.6454 39.368…
```

```r
# how many single-year change data points?
sum(wells4$Interval ==1, na.rm=TRUE)
```

```
## [1] 994
```

```r
# how many years by well?
yearCounts <- wells4 %>% 
  group_by(wellID) %>%
  summarize(n = n_distinct(YearAdj))
hist(yearCounts$n)
```

![](../figure/00.20_wizardFormatting/dataStats-1.png)<!-- -->

```r
# how many wells each year?
wellNums <- wells4 %>%
  group_by(YearAdj) %>%
  summarize(n = n())
summary(wellNums$n)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   26.00   48.25   52.00   49.77   53.00   56.00
```


# Export Cleaned Data
export for downstream analyses


```r
write_sf(wells4, 
         paste0(wellDir,'/cleaned/wells_cleaned_clipped_1996-2017_jimRemoved.shp'))
write_sf(wells4, 
         paste0(wellDir,'/cleaned/wells_cleaned_clipped_1996-2017_jimRemoved.csv'))
```


